{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from deepsphere_unet.deepsphere.laplacian import (\n",
    "    healpix_graph,\n",
    "    prepare_laplacian,\n",
    "    scipy_csr_to_sparse_tensor\n",
    ")\n",
    "from deepsphere_unet.deepsphere.dropout import SpatialConcreteDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Laplacians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAP_DIR = Path(\"lap/\")\n",
    "LAP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lap/lap_1.npz\n",
      "Skipping lap/lap_2.npz\n",
      "Skipping lap/lap_4.npz\n",
      "Skipping lap/lap_8.npz\n",
      "Skipping lap/lap_16.npz\n",
      "Skipping lap/lap_32.npz\n",
      "Skipping lap/lap_64.npz\n",
      "Skipping lap/lap_128.npz\n",
      "Skipping lap/lap_256.npz\n",
      "Skipping lap/lap_512.npz\n"
     ]
    }
   ],
   "source": [
    "ALL_NSIDES = [2**i for i in range(0, 10)]\n",
    "\n",
    "for nside in ALL_NSIDES:\n",
    "    lap_fp = LAP_DIR / f\"lap_{nside}.npz\"\n",
    "    if lap_fp.exists():\n",
    "        print(f\"Skipping {lap_fp}\")\n",
    "        continue\n",
    "    print(f\"Processing {lap_fp}\")\n",
    "    G = healpix_graph(nside, lap_type='combinatorial')\n",
    "    G.compute_laplacian()\n",
    "    some_lap = prepare_laplacian(G.L)\n",
    "    sparse.save_npz(lap_fp, some_lap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSphere Model (With Spatial Concrete Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoding for clarity in parameterizations\n",
    "KERNEL_SIZE = 3\n",
    "NCH = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_laplacian(nside):\n",
    "    \"\"\"Get the Laplacian matrix for a given nside.\"\"\"\n",
    "    lap_fp = LAP_DIR / f\"lap_{nside}.npz\"\n",
    "    if not lap_fp.exists():\n",
    "        raise FileNotFoundError(f\"Laplacian file not found for nside {nside}\")\n",
    "    lap = sparse.load_npz(lap_fp)\n",
    "    lap = scipy_csr_to_sparse_tensor(lap)\n",
    "    return lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheb_conv(laplacian, inputs, weight):\n",
    "    \"\"\"Chebyshev convolution.\n",
    "\n",
    "    Args:\n",
    "        laplacian (:obj:`torch.sparse.Tensor`): The laplacian corresponding to the current sampling of the sphere.\n",
    "        inputs (:obj:`torch.Tensor`): The current input data being forwarded.\n",
    "        weight (:obj:`torch.Tensor`): The weights of the current layer.\n",
    "\n",
    "    Returns:\n",
    "        :obj:`torch.Tensor`: Inputs after applying Chebyshev convolution.\n",
    "    \"\"\"\n",
    "    B, V, Fin = inputs.shape\n",
    "    K, Fin, Fout = weight.shape\n",
    "    # B = batch size\n",
    "    # V = nb vertices\n",
    "    # K = order of Chebyshev polynomials\n",
    "    # Fin = nb input features\n",
    "    # Fout = nb output features\n",
    "\n",
    "    # transform to Chebyshev basis\n",
    "    x0 = inputs.permute(1, 2, 0).contiguous()  # V x Fin x B\n",
    "    x0 = x0.view([V, Fin * B])  # V x Fin*B\n",
    "    inputs = x0.unsqueeze(0)  # 1 x V x Fin*B\n",
    "\n",
    "    if K > 0:\n",
    "        x1 = torch.sparse.mm(laplacian, x0)  # V x Fin*B\n",
    "        inputs = torch.cat((inputs, x1.unsqueeze(0)), 0)  # 2 x V x Fin*B\n",
    "        for _ in range(1, K - 1):\n",
    "            x2 = 2 * torch.sparse.mm(laplacian, x1) - x0\n",
    "            inputs = torch.cat((inputs, x2.unsqueeze(0)), 0)  # M x Fin*B\n",
    "            x0, x1 = x1, x2\n",
    "\n",
    "    inputs = inputs.view([K, V, Fin, B])  # K x V x Fin x B\n",
    "    inputs = inputs.permute(3, 1, 2, 0).contiguous()  # B x V x Fin x K\n",
    "    inputs = inputs.view([B * V, Fin * K])  # B*V x Fin*K\n",
    "\n",
    "    # Linearly compose Fin features to get Fout features\n",
    "    weight = weight.view(Fin * K, Fout)\n",
    "    inputs = inputs.matmul(weight)  # B*V x Fout\n",
    "    inputs = inputs.view([B, V, Fout])  # B x V x Fout\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class ChebConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = KERNEL_SIZE\n",
    "        shape = (self.kernel_size, in_channels, out_channels)\n",
    "        self.weight = nn.Parameter(torch.Tensor(*shape))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        self.xavier_unif_initialization()  # Note that other options are possible\n",
    "\n",
    "    def xavier_unif_initialization(self):\n",
    "        \"\"\"Initialize weights and bias.\n",
    "        \"\"\"\n",
    "        std = math.sqrt(6 / (self.in_channels + self.out_channels))\n",
    "        self.weight.data.uniform_(-std, std)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, lap, x):\n",
    "        out = cheb_conv(lap, x, self.weight)\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    # Copying contents of BayesianSphericalChebBNPool2\n",
    "    def __init__(self, lap, in_c, mid_c, out_c, pooling):\n",
    "        super().__init__()\n",
    "        self.lap = lap\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.conv1 = ChebConv(in_c, mid_c)\n",
    "        self.d_o1 = SpatialConcreteDropout()\n",
    "        self.bn1 = nn.BatchNorm1d(mid_c)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = ChebConv(mid_c, out_c)\n",
    "        self.d_o2 = SpatialConcreteDropout()\n",
    "        self.bn2 = nn.BatchNorm1d(out_c)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = torch.permute(x, (0, 2, 1))\n",
    "            x = self.pooling(x)\n",
    "            x = torch.permute(x, (0, 2, 1))\n",
    "\n",
    "        x = self.d_o1(self.lap, x, self.conv1)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.bn1(x)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.d_o2(self.lap, x, self.conv2)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.bn2(x)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.relu2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, lap, in_c, mid_c, out_c, unpooling):\n",
    "        super().__init__()\n",
    "        self.lap = lap\n",
    "        self.unpooling = unpooling\n",
    "\n",
    "        self.conv1 = ChebConv(in_c, mid_c)\n",
    "        self.d_o1 = SpatialConcreteDropout()\n",
    "        self.bn1 = nn.BatchNorm1d(mid_c)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = ChebConv(mid_c, out_c)\n",
    "        self.d_o2 = SpatialConcreteDropout()\n",
    "        self.bn2 = nn.BatchNorm1d(out_c)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, concat_data):\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.unpooling(x)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = torch.cat((x, concat_data), dim=2)\n",
    "\n",
    "        x = self.d_o1(self.lap, x, self.conv1)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.bn1(x)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.d_o2(self.lap, x, self.conv2)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.bn2(x)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = self.relu2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSphereUNetCD(nn.Module):\n",
    "    def __init__(self, \n",
    "                #  nside\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Makes fixed UNet for testing.\n",
    "\n",
    "        Encoders           Decoders\n",
    "        E3  --------------  D3\n",
    "          E2  ----------  D2\n",
    "            E1  ------  D1\n",
    "                  B\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # self.nside = nside\n",
    "        # self.npix = hp.nside2npix(nside)\n",
    "        # self.kernel_size = 3  # Coded as a global\n",
    "\n",
    "        self.L3_lap = get_laplacian(32)  # Hard-coding Nsides for clarity\n",
    "        self.L2_lap = get_laplacian(16)\n",
    "        self.L1_lap = get_laplacian(8)\n",
    "        self.L0_lap = get_laplacian(4)\n",
    "\n",
    "        pool = nn.MaxPool1d(kernel_size=4)\n",
    "        unpool = nn.Upsample(scale_factor=4, mode='nearest')\n",
    "\n",
    "        # Encoder\n",
    "        self.E3 = EncoderBlock(self.L3_lap, in_c=NCH, mid_c= 32, out_c= 64, pooling=None)\n",
    "        self.E2 = EncoderBlock(self.L2_lap, in_c= 64, mid_c=128, out_c=128, pooling=pool)\n",
    "        self.E1 = EncoderBlock(self.L1_lap, in_c=128, mid_c=256, out_c=256, pooling=pool)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.B  = EncoderBlock(self.L0_lap, in_c=256, mid_c=512, out_c=256, pooling=pool)\n",
    "\n",
    "        # Decoder\n",
    "        self.D1 = DecoderBlock(self.L1_lap, in_c=256+256, mid_c=256, out_c=128, unpooling=unpool)\n",
    "        self.D2 = DecoderBlock(self.L2_lap, in_c=128+128, mid_c=128, out_c= 64, unpooling=unpool)\n",
    "        self.D3 = DecoderBlock(self.L3_lap, in_c= 64+ 64, mid_c= 32, out_c= 16, unpooling=unpool)\n",
    "\n",
    "        # Wrap up\n",
    "        self.dec_fin_mu = torch.nn.Conv1d(16, 1, 1)\n",
    "        self.dec_fin_logvar = torch.nn.Conv1d(16, 1, 1)\n",
    "        self.dec_fin_logvar.weight.data.normal_(0, 1e-6)\n",
    "        self.dec_fin_logvar.bias.data.fill_(0.01)\n",
    "        self.cd_mu = SpatialConcreteDropout(channels_first=True)\n",
    "        self.cd_logvar = SpatialConcreteDropout(channels_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x3 = self.E3(x)\n",
    "        x2 = self.E2(x3)\n",
    "        x1 = self.E1(x2)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.B(x1)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.D1(x, x1)\n",
    "        x = self.D2(x, x2)\n",
    "        x = self.D3(x, x3)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # Wrap up\n",
    "        mu = self.cd_mu(lap=None, x=x, layer=self.dec_fin_mu)\n",
    "        logvar = self.cd_logvar(lap=None, x=x, layer=self.dec_fin_logvar)\n",
    "\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSphereUNetCD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2240, -0.2748,  0.1870,  ...,  0.1870,  0.0469,  0.4153]]],\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]]],\n",
       "        grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nside = 32  # hard-coded above\n",
    "npix = hp.nside2npix(nside)\n",
    "dummy_input = torch.randn(1, npix, NCH)  # 1 sample, npix pixels, NCH channels\n",
    "\n",
    "model(dummy_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmb-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
