defaults:
  - local_system   : generic_lab
  - file_system    : common_fs
  - pipeline       : assembly_deepsphere
  - scenario       : scenario
  - splits         : "2-2"  # If you aren't getting as many results as expected, check n_infer_cap as well
  - model/deepsphere  : basic_deepsphere
  - model/analysis : basic_analysis
  - override hydra/job_logging: custom_log
  - _self_

# dataset_name: CMML_Dataset
# When creating multiple datasets, using interpolation like this may be easier:
dataset_name       : ${scenario.map_fields}_${scenario.nside}_${splits.name}
working_dir        : "Bayesian-Deepsphere-Adams_iso/"
fig_model_name     : DeepSphere
hydra:
  run:
    dir            : Logs/${now:%Y-%m-%d-%H-%M-%S}
  verbose          : true


# Settings below this point are used for interpolation.
# These are not to be used directly in the python
# They are picked up from here and MAY be used elsewhere in the yamls.
# In the scenario yaml
nside              : 32
detectors          : [30, 44, 70, 100, 143, 217, 353, 545, 857]
map_fields         : "I"

# In the model yaml
num_epochs_deterministic : 200
num_epochs_bayesian      : 200

# In the pipeline yamls
# For prediction, postprocessing, power spectra generation:
use_epochs           : &epochs ['init', 'best'] #, 60, 80, 100, 120]
# For single simulation figures (maps & ps figures):
use_epochs_imgs      : ${use_epochs}
# For summary statistics:
use_epochs_map_stats : ${use_epochs}
# For summary statistics:
use_epochs_ps_stats  : ${use_epochs}
# Limit the number of simulations for which to generate figures
n_show_cap           : 2

# Limit the number of simulations on which to do inference and postprocessing
# In the splits yaml; null to run on all
n_infer_cap           : null
run_inference_on      : test  # Either "test" or "valid" ("train" should work, but is not recommended)
